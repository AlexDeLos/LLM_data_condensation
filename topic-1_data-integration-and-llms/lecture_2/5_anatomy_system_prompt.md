## (optional) Anatomy of a system prompt

SOTA models are more and more trained to precisely **follow the instructions** users give them.
This is achieved by using a system prompt that is used to guide the model's behavior.
We can find in the litterature (and probably also in the industry) plenty of examples of very detailed
system prompts aimed at steering chatbots and agents in the right direction. It is important to see
at least one example of such a system prompt. A particular compelling example is the one used by
the **[Biomni agent](https://biomni.stanford.edu)**.

Search for Biomni prompt in the [following pdf](https://biomni.stanford.edu/paper.pdf) and read it.